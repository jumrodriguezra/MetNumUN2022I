{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64mcz4cd2hU7"
      },
      "source": [
        "# Simple iteration for systems of linear equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIkydUXq2hU-"
      },
      "source": [
        "First, generate a random diagonally dominant matrix, for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smXxpLOM2hU_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rndm = np.random.RandomState(1234)\n",
        "\n",
        "n = 10\n",
        "A = rndm.uniform(size=(n, n)) + np.diagflat([15]*n)\n",
        "b = rndm.uniform(size=n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brMXhYVc2hVA"
      },
      "source": [
        "# I.  Jacobi iteration\n",
        "\n",
        "Given\n",
        "\n",
        "$$\n",
        "A x = b\n",
        "$$\n",
        "\n",
        "separate the diagonal part $D$,\n",
        "\n",
        "$$ A = D + (A - D) $$\n",
        "\n",
        "and write\n",
        "\n",
        "$$\n",
        "x = D^{-1} (D - A) x + D^{-1} b\\;.\n",
        "$$\n",
        "\n",
        "Then iterate\n",
        "\n",
        "$$\n",
        "x_{n + 1} = B x_{n} + c\\;,\n",
        "$$\n",
        "\n",
        "where \n",
        "\n",
        "$$\n",
        "B = D^{-1} (A - D) \\qquad \\text{and} \\qquad c = D^{-1} b\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4Gxg78J2hVB"
      },
      "source": [
        "Let's construct the matrix and the r.h.s. for the Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snzwTxOD2hVB"
      },
      "outputs": [],
      "source": [
        "diag_1d = np.diag(A)\n",
        "\n",
        "B = -A.copy()\n",
        "np.fill_diagonal(B, 0)\n",
        "\n",
        "D = np.diag(diag_1d)\n",
        "invD = np.diag(1./diag_1d)\n",
        "BB = invD @ B \n",
        "c = invD @ b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmifw-Ze2hVB"
      },
      "outputs": [],
      "source": [
        "# sanity checks\n",
        "from numpy.testing import assert_allclose\n",
        "\n",
        "assert_allclose(-B + D, A)\n",
        "\n",
        "\n",
        "# xx is a \"ground truth\" solution, compute it using a direct method\n",
        "xx = np.linalg.solve(A, b)\n",
        "\n",
        "np.testing.assert_allclose(A@xx, b)\n",
        "np.testing.assert_allclose(D@xx, B@xx + b)\n",
        "np.testing.assert_allclose(xx, BB@xx + c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzG1mJuP2hVC"
      },
      "source": [
        "Check that $\\| B\\| \\leqslant 1$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOVV05Z82hVC",
        "outputId": "a0e1ed5d-f4b8-4b41-c233-8d6739d9c76f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36436161983015336"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "np.linalg.norm(BB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mWn3hob2hVD"
      },
      "source": [
        "### Do the Jacobi iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1p9SbjF2hVE"
      },
      "outputs": [],
      "source": [
        "n_iter = 50\n",
        "\n",
        "x0 = np.ones(n)\n",
        "x = x0\n",
        "for _ in range(n_iter):\n",
        "    x = BB @ x + c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqIGkp8X2hVE",
        "outputId": "1dadc204-9090-4fde-aa68-c22937e1183e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.11022302e-16,  0.00000000e+00, -2.22044605e-16, -1.11022302e-16,\n",
              "        1.11022302e-16,  0.00000000e+00, -2.08166817e-17,  0.00000000e+00,\n",
              "       -2.77555756e-17,  1.11022302e-16])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Check the result:\n",
        "\n",
        "A @ x - b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S737a55d2hVE"
      },
      "source": [
        "### Task I.1\n",
        "\n",
        "Collect the proof-of-concept above into a single function implementing the Jacobi iteration. This function should receive the r.h.s. matrix $A$, the l.h.s. vector `b`, and the number of iterations to perform.\n",
        "\n",
        "\n",
        "The matrix $A$ in the illustration above is strongly diagonally dominant, by construction. \n",
        "What happens if the diagonal matrix elements of $A$ are made smaller? Check the convergence of the Jacobi iteration, and check the value of the norm of $B$.\n",
        "\n",
        "(20% of the total grade)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Jacobi_iteration(A, b, eps = 1e-12, n_iter = 100):\n",
        "    \n",
        "    diag_1d = np.diag(A)\n",
        "\n",
        "    B = -A.copy()\n",
        "\n",
        "    np.fill_diagonal(B, 0)\n",
        "    invD = np.diag(1./diag_1d)    \n",
        "    BB = invD @ B \n",
        "    c = invD @ b\n",
        "    \n",
        "    x = np.ones(n)\n",
        "    for a in range(n_iter):\n",
        "      \n",
        "        temp = BB @ x + c\n",
        "        if np.linalg.norm(temp - x) < eps: \n",
        "            x = temp\n",
        "            break\n",
        "        x = temp\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "zhRlVOOVCo9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking correctness"
      ],
      "metadata": {
        "id": "jiUbRvbrFYyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = Jacobi_iteration(A, b)\n",
        "\n",
        "np.testing.assert_allclose(A@x, b)\n",
        "np.testing.assert_allclose(x, xx)"
      ],
      "metadata": {
        "id": "XePZmPV0EN01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making diagonal smaller, check for convergence"
      ],
      "metadata": {
        "id": "PUU-i2uQFkxe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxEiy4rn2hVG",
        "outputId": "65a39bce-92ca-4f2c-d62b-0e877bae66ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Norm of B 0.38959181027260875 Convergence: 2.005305120107153e-17\n",
            "2. Norm of B 0.4185783948614869 Convergence: 1.6502682545529e-17\n",
            "3. Norm of B 0.4522284025473819 Convergence: 3.622208959480119e-17\n",
            "4. Norm of B 0.4917667095178099 Convergence: 2.72080745804227e-17\n",
            "5. Norm of B 0.5388887887486234 Convergence: 2.5332308935446513e-17\n",
            "6. Norm of B 0.5960110344093966 Convergence: 2.715271730114205e-17\n",
            "7. Norm of B 0.6667001660296402 Convergence: 3.1986720415755645e-17\n",
            "8. Norm of B 0.7564517359241753 Convergence: 4.2668555758937507e-17\n",
            "9. Norm of B 0.8742017351588476 Convergence: 1.306888029984837e-14\n",
            "10. Norm of B 1.0355299928250665 Convergence: 2.726494964669312e-07\n",
            "11. Norm of B 1.2702850939751231 Convergence: 178.83641240483422\n",
            "12. Norm of B 1.6439565658213244 Convergence: 22252505496170.793\n",
            "13. Norm of B 2.334809111760855 Convergence: 2.2347420503806264e+28\n",
            "14. Norm of B 4.080768845910033 Convergence: 6.13577109020183e+51\n",
            "15. Norm of B 30.715327603064885 Convergence: 7.280323737239156e+121\n",
            "16. Norm of B 25.668433387443834 Convergence: 1.5242880192258558e+111\n",
            "17. Norm of B 3.8385533278362765 Convergence: 4.917774713283019e+49\n",
            "18. Norm of B 2.2533561772001827 Convergence: 1.1558547003009474e+27\n",
            "19. Norm of B 1.6031859449057577 Convergence: 1682490334347.9482\n",
            "20. Norm of B 1.24581575811634 Convergence: 167.67712324660263\n",
            "21. Norm of B 1.019215329207032 Convergence: 1.4131993401963568e-07\n",
            "22. Norm of B 0.8625478003698426 Convergence: 6.352814114282221e-15\n",
            "23. Norm of B 0.7477110355740726 Convergence: 1.0477500027681816e-16\n",
            "24. Norm of B 0.6599017255790174 Convergence: 4.6027415078689346e-17\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 25):\n",
        "\n",
        "    A_i = A + np.diagflat([-i]*n)\n",
        "    norm_b = np.linalg.norm(np.diag(1./np.diag(A_i))@(-A_i.copy()+np.diag(np.diag(A_i))))\n",
        "    convergence = np.linalg.norm(Jacobi_iteration(A_i, b)-np.linalg.solve(A_i, b))\n",
        "\n",
        "    print(str(i)+\".\",\n",
        "          \"Norm of B\", norm_b,\n",
        "          \"Convergence:\", convergence)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65t40l-82hVG"
      },
      "source": [
        "# II. Seidel's iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4ZIPWnA2hVH"
      },
      "source": [
        "##### Task II.1\n",
        "\n",
        "Implement the Seidel's iteration. \n",
        "\n",
        "Test it on a random matrix. Study the convergence of iterations, relate to the norm of the iteration matrix.\n",
        "\n",
        "(30% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IHqGxyZ2hVH"
      },
      "outputs": [],
      "source": [
        "def seidel_iteration(A, b, eps = 1e-12, n_iter = 50):\n",
        "    \n",
        "    x = np.zeros(len(b))\n",
        "    \n",
        "    for i in range(n_iter):\n",
        "      x_copy = x.copy()\n",
        "\n",
        "      for j in range(b.shape[0]):\n",
        "        x_copy[j] = (b[j]-np.dot(A[j][:j], x[:j])- np.dot(A[j][j+1:], x[j+1:]))/A[j,j]\n",
        "      \n",
        "      if np.linalg.norm(x_copy - x, ord=np.inf) / np.linalg.norm(x_copy, ord=np.inf) < eps:\n",
        "        x = x_copy\n",
        "        break\n",
        "\n",
        "      x = x_copy\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking correctness"
      ],
      "metadata": {
        "id": "bhv_Ui6aRugV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlcKRuZp2hVH"
      },
      "outputs": [],
      "source": [
        "x = seidel_iteration(A,b)\n",
        "\n",
        "np.testing.assert_allclose(A@x, b)\n",
        "np.testing.assert_allclose(x, xx)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making diagonal smaller, check for convergence"
      ],
      "metadata": {
        "id": "jWGRZ_atRugY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSOwLG_v2hVI",
        "outputId": "1e38db17-3c9a-44d2-c8de-cc3afcbb6832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Norm of B 0.38959181027260875 Convergence: 1.441843549426575e-14\n",
            "2. Norm of B 0.4185783948614869 Convergence: 3.377066387387329e-14\n",
            "3. Norm of B 0.4522284025473819 Convergence: 3.984221259521332e-14\n",
            "4. Norm of B 0.4917667095178099 Convergence: 3.174930488165913e-14\n",
            "5. Norm of B 0.5388887887486234 Convergence: 5.48869792195361e-14\n",
            "6. Norm of B 0.5960110344093966 Convergence: 5.620681427479863e-14\n",
            "7. Norm of B 0.6667001660296402 Convergence: 7.886279447627353e-14\n",
            "8. Norm of B 0.7564517359241753 Convergence: 7.643869710323461e-12\n",
            "9. Norm of B 0.8742017351588476 Convergence: 1.1267351603270573e-08\n",
            "10. Norm of B 1.0355299928250665 Convergence: 5.682933757898043e-05\n",
            "11. Norm of B 1.2702850939751231 Convergence: 1.6249187890365402\n",
            "12. Norm of B 1.6439565658213244 Convergence: 649343.4829966454\n",
            "13. Norm of B 2.334809111760855 Convergence: 23791844542337.92\n",
            "14. Norm of B 4.080768845910033 Convergence: 1.4925298432550307e+25\n",
            "15. Norm of B 30.715327603064885 Convergence: 2.508140171395458e+60\n",
            "16. Norm of B 25.668433387443834 Convergence: 9.589308381830487e+54\n",
            "17. Norm of B 3.8385533278362765 Convergence: 2.5324211576365357e+24\n",
            "18. Norm of B 2.2533561772001827 Convergence: 19423531724778.863\n",
            "19. Norm of B 1.6031859449057577 Convergence: 1734097.3491629474\n",
            "20. Norm of B 1.24581575811634 Convergence: 58.03569953225956\n",
            "21. Norm of B 1.019215329207032 Convergence: 0.000346104163083775\n",
            "22. Norm of B 0.8625478003698426 Convergence: 3.8984987803995614e-08\n",
            "23. Norm of B 0.7477110355740726 Convergence: 2.02240922786859e-11\n",
            "24. Norm of B 0.6599017255790174 Convergence: 3.334347481127101e-13\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 25):\n",
        "\n",
        "    A_i = A + np.diagflat([-i]*n)\n",
        "    norm_b = np.linalg.norm(np.diag(1./np.diag(A_i))@(-A_i.copy()+np.diag(np.diag(A_i))))\n",
        "    convergence = np.linalg.norm(seidel_iteration(A_i, b)-np.linalg.solve(A_i, b))\n",
        "\n",
        "    print(str(i)+\".\",\n",
        "          \"Norm of B\", norm_b,\n",
        "          \"Convergence:\", convergence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raFVZjsb2hVI"
      },
      "source": [
        "# III. Minimum residual scheme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8akOCBA2hVJ"
      },
      "source": [
        "### Task III.1\n",
        "\n",
        "Implement the $\\textit{minimum residual}$ scheme: an explicit non-stationary method, where at each step you select the iteration parameter $\\tau_n$ to minimize the residual $\\mathbf{r}_{n+1}$ given $\\mathbf{r}_n$. Test it on a random matrix, study the convergence to the solution, in terms of the norm of the residual and the deviation from the ground truth solution (which you can obtain using a direct method). Study how the iteration parameter $\\tau_n$ changes as iterations progress.\n",
        "\n",
        "(50% of the grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl8G1z782hVJ"
      },
      "outputs": [],
      "source": [
        "def minimum_res_scheme(A, b, eps = 1e-12, n_iter = 100):\n",
        "    \n",
        "    x = np.zeros(len(b))\n",
        "    x_copy = np.zeros(len(b))\n",
        "\n",
        "    for i in range(n_iter):\n",
        "      residual = A @ x - b\n",
        "      tau = (residual @ A @ residual) / np.dot( A @ residual, A @ residual )\n",
        "      x_copy = x- tau*residual\n",
        "\n",
        "      if np.linalg.norm(x_copy - x) < eps:\n",
        "        x = x_copy \n",
        "        break\n",
        "      x = x_copy\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking correctness"
      ],
      "metadata": {
        "id": "I5H09LWlRypv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D784owEO2hVJ"
      },
      "outputs": [],
      "source": [
        "x = minimum_res_scheme(A,b)\n",
        "\n",
        "np.testing.assert_allclose(A@x, b)\n",
        "np.testing.assert_allclose(x, xx)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making diagonal smaller, check for convergence"
      ],
      "metadata": {
        "id": "alsbKo9ERypw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apdAfyOS2hVK",
        "outputId": "1a814a60-f8f9-486c-aa20-ee76ddc84926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Norm of B 0.38959181027260875 Convergence: 6.673028063636746e-14\n",
            "2. Norm of B 0.4185783948614869 Convergence: 1.767697481147239e-13\n",
            "3. Norm of B 0.4522284025473819 Convergence: 7.368052439887803e-14\n",
            "4. Norm of B 0.4917667095178099 Convergence: 5.5194981071777194e-14\n",
            "5. Norm of B 0.5388887887486234 Convergence: 2.1579490351292104e-13\n",
            "6. Norm of B 0.5960110344093966 Convergence: 1.9335756405058914e-13\n",
            "7. Norm of B 0.6667001660296402 Convergence: 3.1197922640425305e-13\n",
            "8. Norm of B 0.7564517359241753 Convergence: 2.0319648079364555e-13\n",
            "9. Norm of B 0.8742017351588476 Convergence: 2.944061117089313e-13\n",
            "10. Norm of B 1.0355299928250665 Convergence: 4.79355622288367e-13\n",
            "11. Norm of B 1.2702850939751231 Convergence: 3.0887364779793784e-13\n",
            "12. Norm of B 1.6439565658213244 Convergence: 6.004620874100477e-13\n",
            "13. Norm of B 2.334809111760855 Convergence: 1.5917901613494577e-12\n",
            "14. Norm of B 4.080768845910033 Convergence: 1.863422634148316e-08\n",
            "15. Norm of B 30.715327603064885 Convergence: 1.7352125977116704\n",
            "16. Norm of B 25.668433387443834 Convergence: 1.3647831880315497\n",
            "17. Norm of B 3.8385533278362765 Convergence: 0.68930290984813\n",
            "18. Norm of B 2.2533561772001827 Convergence: 0.8538536353938408\n",
            "19. Norm of B 1.6031859449057577 Convergence: 1.7472765346895545\n",
            "20. Norm of B 1.24581575811634 Convergence: 16.196509380073056\n",
            "21. Norm of B 1.019215329207032 Convergence: 4.578821758960614e-12\n",
            "22. Norm of B 0.8625478003698426 Convergence: 1.0079891360849092e-12\n",
            "23. Norm of B 0.7477110355740726 Convergence: 3.635985607165662e-13\n",
            "24. Norm of B 0.6599017255790174 Convergence: 1.6557655050408509e-13\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 25):\n",
        "\n",
        "    A_i = A + np.diagflat([-i]*n)\n",
        "    norm_b = np.linalg.norm(np.diag(1./np.diag(A_i))@(-A_i.copy()+np.diag(np.diag(A_i))))\n",
        "    convergence = np.linalg.norm(minimum_res_scheme(A_i, b)-np.linalg.solve(A_i, b))\n",
        "\n",
        "    print(str(i)+\".\",\n",
        "          \"Norm of B\", norm_b,\n",
        "          \"Convergence:\", convergence)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Week4IterativeMethodsForLinearSystemsGroup7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}